#install.packages("qcc")
#install.packages("readxl")
#install.packages("dummies")
#install.packages("caret")
#install.packages("dplyr")
#install.packages("fastDummies")
library(qcc)
library(readxl)
library(fastDummies)
library(reshape)
library(caret)
library(dplyr)

set.seed(13)

#Reading Data and creating training and testing data
dataset = read_excel('/Users/Krupal/My_Stuff/ADBI/Projects and Assignments/GLM Logistic Regression HW Resources-20200124/eBayAuctions.xls')
colnames(dataset)[8] = "Competitive"
print(dataset)
dataset = as.data.frame(dataset)
split_index = createDataPartition(dataset$'Competitive', p = 0.6, list = FALSE)
training_Data = dataset[split_index,]
test_Data = dataset[-split_index,]
print("Training Dataset: ")
print(training_Data)
print("Test Dataset: ")
print(test_Data)


#Function for creating pivot tables
function_pivot <- function(pivot_table){
  threeshold = 0.04
  pivot_table['temp_merge'] = pivot_table[1]
  table_length = dim(pivot_table)[1]
  for(i in 1:(table_length-1)){
    for(j in (i+1):table_length){
      if(j<=table_length){
        #print(abs(pivot_table[i,2] - pivot_table[j,2]))
        #Comparing the current row and the subsequent row and if the difference is significant then only we'll keep it in our pivot table
        if(abs(pivot_table[i,2] - pivot_table[j,2]) < threeshold){
          pivot_table[j,3] = pivot_table[i,3]
        }
      }
    }
  }
  return (pivot_table)
  
}

#Creating pivot tables 
training_Data.melt = melt(training_Data, id.vars = c("Category","currency","Duration","endDay"), measure.vars = "Competitive")
#print(training_Data.melt)
pivot_table_category = cast(training_Data.melt, Category ~ variable, mean)
print("Pivot Table for Category Attribute: ")
print(pivot_table_category)
pivot_table_currency = cast(training_Data.melt, currency ~ variable, mean)
print("Pivot Table for Currency Attribute: ")
print(pivot_table_currency)
pivot_table_Duration = cast(training_Data.melt, Duration ~ variable, mean)
print("Pivot Table for Duration Attribute: ")
print(pivot_table_Duration)
pivot_table_endDay = cast(training_Data.melt, endDay ~ variable, mean)
print("Pivot Table for endDay Attribute: ")
print(pivot_table_endDay)


#Merging categories in order to reduce the number of dummies in the model
pivot_table = function_pivot(pivot_table_category)
len = dim(pivot_table)[1]
for (i in 1:len) {
  training_Data[training_Data['Category']==pivot_table[i,1], 'Category'] = pivot_table[i,3]
  test_Data[test_Data['Category']==pivot_table[i,1], 'Category'] = pivot_table[i,3]
}

pivot_table = function_pivot(pivot_table_currency)
len = dim(pivot_table)[1]
for (i in 1:len) {
  training_Data[training_Data['currency']==pivot_table[i,1], 'currency'] = pivot_table[i,3]
  test_Data[test_Data['currency']==pivot_table[i,1], 'currency'] = pivot_table[i,3]
}

pivot_table = function_pivot(pivot_table_Duration)
len = dim(pivot_table)[1]
for (i in 1:len) {
  training_Data[training_Data['Duration']==pivot_table[i,1], 'Duration'] = pivot_table[i,3]
  test_Data[test_Data['Duration']==pivot_table[i,1], 'Duration'] = pivot_table[i,3]
}

pivot_table = function_pivot(pivot_table_endDay)
len = dim(pivot_table)[1]
for (i in 1:len) {
  training_Data[training_Data['endDay']==pivot_table[i,1], 'endDay'] = pivot_table[i,3]
  test_Data[test_Data['endDay']==pivot_table[i,1], 'endDay'] = pivot_table[i,3]
}


#Creating dummy variables
training_Data = dummy_cols(training_Data,select_columns = c("Category","currency","Duration","endDay"),split = "_")
training_Data = within(training_Data, rm("Category", "currency","Duration","endDay"))
print("Training Data with dummy variables: ")
print(training_Data)
test_Data = dummy_cols(test_Data,select_columns = c("Category","currency","Duration","endDay"), split = "_")
test_Data= within(test_Data, rm("Category", "currency","Duration","endDay"))
print("Test Data with Dummy Variables: ")
print(test_Data)

#Fit.all and fit.single 
fit.all <- glm(Competitive ~.,family = binomial(link = "logit"),data = training_Data )
summary_fit = summary(fit.all)
print(summary_fit)
len = length(fit.all$coefficients)
max_value = -99999999
feature = NA
temp_1 = 0
for(i in 1:len){
  if(is.na(fit.all$coefficients[i])){
    fit.all$coefficients[i] = 0
  }
  if(abs(fit.all$coefficients[i])>max_value){
    #print(fit.all$coefficients[i])
    max_value = abs(fit.all$coefficients[i])
    #print(names(fit.all$coefficients[i]))
    temp_1 = i
    feature = names(fit.all$coefficients[i])
  }
}
#Dealing with extra '`' generated by dummy_cols
if(substr(feature,1,1) == '`'){
  feature = substr(feature,2,nchar(feature)-1)
  print(TRUE)
}

cat("Feature with the highest estimate:",toString(feature))
temp = c("Competitive",feature)
fit.single <- glm(Competitive ~. ,family = binomial(link = "logit"),data = training_Data[temp]) 
print(summary(fit.single))

  
#Building model using fit.reduced by finding statistically significant models

significance_estimate = summary(fit.all)$coefficients[,4]
final_model = "`Competitive` ~ "
attributes_model = c("Competitive")
temp = TRUE
for(i in 1:length(significance_estimate)){
  if(significance_estimate[i]<0.05){
    if(temp){
      final_model = paste(final_model,names(significance_estimate[i]),"")
      attributes_model = c(attributes_model,names(significance_estimate[i]))
      temp = FALSE
      
    }
    else{
      final_model = paste(final_model,"+",names(significance_estimate[i]))
      attributes_model = c(attributes_model,names(significance_estimate[i]))
    }
  }
}

fit.reduced = glm(final_model,family = binomial(link = "logit"),data = training_Data)
summary_reduced_fit = summary(fit.reduced)
print(summary_reduced_fit)

#Testing the fit_reduced model
anova(fit.reduced,fit.all,test = "Chisq")

#Testing for Overdispersion
cat("Dispersion of the model: ",(fit.reduced$deviance/fit.all$df.residual))

sample=rep(length(training_Data$Competitive), length(training_Data$Competitive))
qcc.overdispersion.test(training_Data$Competitive, size=sample, type="binomial")
